{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XO8_1lNAr_T1",
    "papermill": {
     "duration": 0.015145,
     "end_time": "2020-10-01T00:25:28.586307",
     "exception": false,
     "start_time": "2020-10-01T00:25:28.571162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "Pandas is a tool invented at a financial investment firm that has become a leading open-source library for accessing and analyzing data in many different fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T00:25:28.623916Z",
     "iopub.status.busy": "2020-10-01T00:25:28.623025Z",
     "iopub.status.idle": "2020-10-01T00:25:28.628773Z",
     "shell.execute_reply": "2020-10-01T00:25:28.627859Z"
    },
    "id": "cl8PGV86r_T1",
    "papermill": {
     "duration": 0.027289,
     "end_time": "2020-10-01T00:25:28.628978",
     "exception": false,
     "start_time": "2020-10-01T00:25:28.601689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uKH0_fPr_T2",
    "papermill": {
     "duration": 0.015807,
     "end_time": "2020-10-01T00:25:28.661215",
     "exception": false,
     "start_time": "2020-10-01T00:25:28.645408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Return to the cell with the import and rewrite it like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omRNMYEUr_T2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G2WffRGZr_T2"
   },
   "source": [
    "This will import the pandas library at the shorter variable name of pd. This is not required but it is standard practice in the pandas community and you will frequently see examples of pandas code online using it as shorthand. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6ymdOi7r_T2",
    "papermill": {
     "duration": 0.01564,
     "end_time": "2020-10-01T00:25:28.693049",
     "exception": false,
     "start_time": "2020-10-01T00:25:28.677409",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# A simple data analysis\n",
    "\n",
    "\n",
    "Those two little letters contain dozens of data analysis tools that we’ll use in future lessons.\n",
    "\n",
    "They can import massive data files, compute advanced statistics, filter, sort, rank and just about anything else you’d want to do.\n",
    "\n",
    "We’ll get to that soon, but let’s start out with something simple.\n",
    "\n",
    "First let’s make a list of numbers in a new notebook cell. To keep things simple, I am going to enter all of the even numbers between zero and ten and press play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T00:25:28.733539Z",
     "iopub.status.busy": "2020-10-01T00:25:28.732497Z",
     "iopub.status.idle": "2020-10-01T00:25:28.735338Z",
     "shell.execute_reply": "2020-10-01T00:25:28.735936Z"
    },
    "id": "6apdpURnr_T3",
    "papermill": {
     "duration": 0.0258,
     "end_time": "2020-10-01T00:25:28.736101",
     "exception": false,
     "start_time": "2020-10-01T00:25:28.710301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_list = [2, 4, 6, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wU_3bg2Zr_T3",
    "papermill": {
     "duration": 0.015777,
     "end_time": "2020-10-01T00:25:28.768332",
     "exception": false,
     "start_time": "2020-10-01T00:25:28.752555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "If you’re a skilled Python programmer, you can do some cool stuff with any list. But hand it over to pandas instead, and you can analyze it without knowing much computer code at all.\n",
    "\n",
    "In this case, it’s as simple as converting that plain Python list into what pandas calls a Series. Make it happen in your next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-01T00:25:28.808325Z",
     "iopub.status.busy": "2020-10-01T00:25:28.807548Z",
     "iopub.status.idle": "2020-10-01T00:25:28.845747Z",
     "shell.execute_reply": "2020-10-01T00:25:28.845110Z"
    },
    "id": "UaoeSFscr_T3",
    "papermill": {
     "duration": 0.061497,
     "end_time": "2020-10-01T00:25:28.845943",
     "exception": false,
     "start_time": "2020-10-01T00:25:28.784446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_series = pd.Series(my_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HHIcAEbKr_T3",
    "papermill": {
     "duration": 0.015929,
     "end_time": "2020-10-01T00:25:28.878274",
     "exception": false,
     "start_time": "2020-10-01T00:25:28.862345",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Once the data becomes a Series, you can immediately run a wide range of descriptive statistics. Let’s try a few.\n",
    "\n",
    "First, let’s sum all the numbers. Make a new cell and run this. It should spit out the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2020-10-01T00:25:28.918639Z",
     "iopub.status.busy": "2020-10-01T00:25:28.917871Z",
     "iopub.status.idle": "2020-10-01T00:25:28.939440Z",
     "shell.execute_reply": "2020-10-01T00:25:28.938656Z"
    },
    "id": "wOWVs2tvr_T3",
    "outputId": "14eaf534-304e-4084-a1da-9a43fb3863e8",
    "papermill": {
     "duration": 0.044993,
     "end_time": "2020-10-01T00:25:28.939563",
     "exception": false,
     "start_time": "2020-10-01T00:25:28.894570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_series.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1n6UnbgWr_T4",
    "papermill": {
     "duration": 0.017239,
     "end_time": "2020-10-01T00:25:28.973791",
     "exception": false,
     "start_time": "2020-10-01T00:25:28.956552",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Then find the maximum value in the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2020-10-01T00:25:29.016427Z",
     "iopub.status.busy": "2020-10-01T00:25:29.015441Z",
     "iopub.status.idle": "2020-10-01T00:25:29.020325Z",
     "shell.execute_reply": "2020-10-01T00:25:29.019661Z"
    },
    "id": "emBhvLWzr_T4",
    "outputId": "2085fda2-edac-4855-8b03-87e5d4db8e03",
    "papermill": {
     "duration": 0.029678,
     "end_time": "2020-10-01T00:25:29.020453",
     "exception": false,
     "start_time": "2020-10-01T00:25:28.990775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_series.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfNp_WVTr_T4"
   },
   "source": [
    "The minimum value in the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FT6Wykzrr_T4",
    "outputId": "980fed7b-e89d-4732-e84d-4daab9d5166e"
   },
   "outputs": [],
   "source": [
    "my_series.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEpQv3Vmr_T4"
   },
   "source": [
    "How about the average (also known as the mean)? Keep adding cells and calculating new statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQE3CUx-r_T4",
    "outputId": "89fac997-8936-42f1-d6ad-95bf60c925ea"
   },
   "outputs": [],
   "source": [
    "my_series.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bBWnP3TTr_T5"
   },
   "source": [
    "The median?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "neHSus6er_T5",
    "outputId": "f16b3e58-805e-4057-f099-c96a2ef7932b"
   },
   "outputs": [],
   "source": [
    "my_series.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TI2uTSGr_T5"
   },
   "source": [
    "The standard deviation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "geEJmkKar_T5",
    "outputId": "44810203-fa66-4cc2-f9c9-99d84a342f37"
   },
   "outputs": [],
   "source": [
    "my_series.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHCdFA5Cr_T5"
   },
   "source": [
    "And all of the above, plus a little more about the distribution, in one simple command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S0oPWhEJr_T5",
    "outputId": "1c0a237c-6631-471b-8c27-c410ed7a9ddd"
   },
   "outputs": [],
   "source": [
    "my_series.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22YzQ4Jir_T5"
   },
   "source": [
    "With those simple techniques, we’re only scratching the surface of what pandas makes possible.\n",
    "\n",
    "Substitute in a series of 10 million records at the top of the stack (or even just the odd numbers between zero and ten), and your notebook would calculate all those statistics again without you having to write any more code.\n",
    "\n",
    "Once your data, however large or complex, is imported into pandas, there’s little limit to what you can do to filter, merge, group, aggregate, compute or chart using simple methods like the ones above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wT_GQhuVr_T6"
   },
   "source": [
    "# Data\n",
    "Now it’s time to get our hands on some real data.\n",
    "\n",
    "Our data source will be the California Civic Data Coalition, an open-source network of journalists and developers that maintains an archive of data tracking money in California politics.\n",
    "\n",
    "The coalition has created simplified data files containing the disclosure forms that committees campaigning either for against one of the 17 propositions on the ballot in November 2016 filed with the state of California.\n",
    "\n",
    "They are:\n",
    "\n",
    "* committees.csv\t- Committees active in the election linked to propositions supported or opposed\n",
    "* contributions.csv - Donors reported by each of the committees\n",
    "\n",
    "The data are structured in rows of comma-separated values. This is known as a CSV file. It is the most common way you will find data published online.\n",
    "\n",
    "## Creating a DataFrame\n",
    "The pandas library is able to read in files from a variety formats, including CSV.\n",
    "\n",
    "If it’s not currently running start up your Jupyter Notebook.\n",
    "\n",
    "Scroll down to the first open cell. There we will import the first CSV file listed above using the read_csv function included with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yHZzolGYSJ-o",
    "outputId": "c4d1e139-d8d8-486e-9556-1a89c4448cb1"
   },
   "outputs": [],
   "source": [
    "pd.read_csv('committees.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVYjEPqQr_T6"
   },
   "source": [
    "After you run the cell, you should see a big table printed below.\n",
    "\n",
    "It is a DataFrame where pandas has structured the CSV data into rows and columns, just like Excel or other spreadsheet software might.\n",
    "\n",
    "The advantage here is that rather than manipulating the data through a haphazard series of clicks and keypunches we will be gradually grinding down the data using a computer programming script that is 100% transparent and reproducible.\n",
    "\n",
    "## Creating a variable\n",
    "In order to do that, we need to store our DataFrame so it can be reused in subsequent cells. We can do this by saving in a “variable”, which is a fancy computer programming word for a named shortcut where we save our work as we go.\n",
    "\n",
    "Go back to your initial cell and change it to this. Then rerun it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jtdT2455r_T7"
   },
   "outputs": [],
   "source": [
    "committee_list = pd.read_csv(\"committees.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jfVigRSIr_T7"
   },
   "source": [
    "After you run it, you shouldn’t see anything. That’s a good thing. It means our DataFrame has been saved under the name props, which we can now begin interacting with in the cells that follow.\n",
    "\n",
    "We can do this by calling “methods” that pandas has made available to all DataFrames.\n",
    "\n",
    "You may not have known it at the time, but read_csv was one of these methods. There are dozens more that can do all sorts of interesting things. Let’s start with some easy ones that analysts use all the time.\n",
    "\n",
    "## Using the head method\n",
    "First, to preview the first few rows of the dataset, try the head method. Hit the + button in the toolbar to add a new cell below the first one. Type this in it and hit the run button again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "0w3C8ddYr_T8",
    "outputId": "fd249097-5960-41a5-9005-8ecafd64d871"
   },
   "outputs": [],
   "source": [
    "committee_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qb4WYK-Fr_T8"
   },
   "source": [
    "## Using the info method\n",
    "To get a look at all of the columns and what type of data they store, add another cell and try info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Ql1PdICr_T8",
    "outputId": "a718bd6d-0d2a-40f1-e155-c9908c0af5cd"
   },
   "outputs": [],
   "source": [
    "committee_list.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPVXBIOwr_T8"
   },
   "source": [
    "Look carefully at those results and you see we have more than 100 links between committees and propositions.\n",
    "\n",
    "## Creating another DataFrame\n",
    "With that we’re ready to move on to a related, similar task: Importing all of the individual contributions reported to last year’s 17 ballot measures.\n",
    "\n",
    "We’ll start by using the read_csv method to import the second CSV file linked above. Save it as a new variable just as we did before. Let’s call this one contribs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cq4XXlxxr_T9"
   },
   "outputs": [],
   "source": [
    "contrib_list = pd.read_csv(\"contributions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMMrz4OWr_T9"
   },
   "source": [
    "Just as we did earlier, you can inspect the contents of this new file with the head method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "rrTHRXGvr_T9",
    "outputId": "921cfa5b-bbca-4170-e4b7-ba96887de4fe"
   },
   "outputs": [],
   "source": [
    "contrib_list.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3jTXgXwmr_T-"
   },
   "source": [
    "You should also inspect the columns using the info method. Running these two tricks whenever you open a new file is a good habit to develop so that you can carefully examine the data you’re about to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WAYbMldtr_T-",
    "outputId": "2aea40ad-c371-4870-ac0c-0424c1bbec1e"
   },
   "outputs": [],
   "source": [
    "contrib_list.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfA-FrQmr_T-"
   },
   "source": [
    "# Columns\n",
    "In this section we’ll begin our analysis by learning how to inspect a column from a DataFrame.\n",
    "\n",
    "## Accessing a column\n",
    "We’ll begin with the prop_name column where the proposition each committee sought to influence is stored.\n",
    "\n",
    "To see the contents of a column separate from the rest of the DataFrame, add the column’s name to the DataFrame’s variable following a period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NYkpbTsSr_T-",
    "outputId": "d1ff3def-e35c-40f2-bc19-0bdcc4aee214"
   },
   "outputs": [],
   "source": [
    "committee_list.prop_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8wBRK7rr_T-"
   },
   "source": [
    "That will list the column out as a Series, just like the ones we created from scratch in chapter three.\n",
    "\n",
    "And, just as we did then, you can now start tacking on additional methods that will analyze the contents of the column.\n",
    "\n",
    "In this case, the column is filled with characters. So we don’t want to calculate statistics like the median and average, as we did before.\n",
    "\n",
    "You can also access columns a second way, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yUXFad-ar_T_",
    "outputId": "34a74f40-2dc3-4bb1-ab6a-68c1d4c8b430"
   },
   "outputs": [],
   "source": [
    "committee_list['prop_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b0AjhoMqr_T_"
   },
   "source": [
    "This method isn’t as pretty, but it’s required if your column has a space in its name, which would break the simpler dot-based method.\n",
    "\n",
    "## Counting a column’s values\n",
    "There’s another built-in pandas tool that will total up the frequency of values in a column. In this case that could be used to answer the question: Which proposition had the most committees?\n",
    "\n",
    "The method is called value_counts and it’s just as easy to use as sum, min or max. All you need to do it is add a period after the column name and chain it on the tail end of your cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TIpaeUL0r_T_",
    "outputId": "f8c5a537-ab8c-45db-c8eb-c778f2e00f08"
   },
   "outputs": [],
   "source": [
    "committee_list.prop_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wsGRcp0_r_T_"
   },
   "source": [
    "Run the code and you should see the lengthy proposition names ranked by their number of committees.\n",
    "\n",
    "\n",
    "## Resetting a DataFrame\n",
    "You may have noticed that even though the result has two columns, pandas did not return a clean-looking table in the same way as head did for our DataFrame.\n",
    "\n",
    "That’s because our column, a Series, acts a little bit different than the DataFrame created by read_csv.\n",
    "\n",
    "In most instances, if you have an ugly Series generated by a method like value_counts and you want to convert it into a pretty DataFrame you can do so by tacking on the reset_index method onto the tail end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "GIM_abccr_T_",
    "outputId": "04c5a488-046a-411a-ce2f-3333f49089e3"
   },
   "outputs": [],
   "source": [
    "committee_list.prop_name.value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tdqCU5nr_T_"
   },
   "source": [
    "Why do Series and DataFrames behave differently? Why does reset_index have such a weird name?\n",
    "\n",
    "Like so much in computer programming, the answer is simply “because the people who created the library said so.”\n",
    "\n",
    "That’s not worth stressing about in this case, but it’s important to learn that all open-source programming tools have their quirks. Over time you’ll learn pandas has more than a few.\n",
    "\n",
    "As a beginner, you should just accept the oddities and roll with it. As you get more advanced, if there’s something about the system you think could be improved you should consider contributing to the Python code that operates the library you’d like to improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PMyKMTTr_T_"
   },
   "source": [
    "# Filters\n",
    "Until November 2016, the use and sale of marijuana for recreational purposes was illegal in California. That changed when voters approved Proposition 64, which asked if the practice ought to be legalized.\n",
    "\n",
    "A yes vote supported legalization. A no vote opposed it. In the final tally, 57% of voters said yes.\n",
    "\n",
    "Our next mission is to use the DataFrames containing campaign committees and contributors to figure out the biggest donors both for and against the measure.\n",
    "\n",
    "To do that, the first thing we need to do is isolate the fundraising committees active on Proposition 64, which are now buried among of the list of more than 100 groups active last November.\n",
    "\n",
    "## Filtering a DataFrame\n",
    "The most common way to filter a DataFrame is to pass an expression as an “index” that can be used to decide which records should be kept and which discarded.\n",
    "\n",
    "You write the expression by combining a column on your DataFrame with an “operator” like == or > or < and a value to compare the column against.\n",
    "\n",
    "If you are familiar with writing SQL to manipulate databases, pandas’ filtering system is somewhat similar to a WHERE query. The official pandas documentation offers direct translations between the two.\n",
    "\n",
    "In our case, the column we want to filter against is prop_name. We only want to keep those records where the value there matches the full name of Proposition 64.\n",
    "\n",
    "Where do we get that? Our friend value counts.\n",
    "\n",
    "Running the command we learned before to list and count all of the proposition names will spit out the full name of all 17 measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WjncgCvdr_T_"
   },
   "outputs": [],
   "source": [
    "committee_list.prop_name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lny4F144r_T_"
   },
   "source": [
    "From that result we can copy the full name of the proposition and place it between quotation marks in a variable in a new cell. This will allow us to reuse it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHqqiEzsr_UA"
   },
   "outputs": [],
   "source": [
    "my_prop = 'PROPOSITION 064- MARIJUANA LEGALIZATION. INITIATIVE STATUTE.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9CyP23wr_UA"
   },
   "source": [
    "In the next cell we will ask pandas to narrow down our list of committees to just those that match the proposition we’re interested in. We will create a filter expression that looks like this: committee_list.prop_name == my_prop, and place it between two flat brackets following the variable we want to filter. Place the following code in the next open cell in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybr5qO5Rr_UA"
   },
   "outputs": [],
   "source": [
    "committee_list[committee_list.prop_name == my_prop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-puXU3z-r_UA"
   },
   "source": [
    "Run it and it outputs the filtered dataset, just those committees active on Proposition 64.\n",
    "\n",
    "Now we should save the results of that filter into new variable separate from the full list we imported from the CSV file.\n",
    "\n",
    "Since it includes only the committees for one proposition lets call it the singular prop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xO2CYLHdr_UA"
   },
   "outputs": [],
   "source": [
    "my_committees = committee_list[committee_list.prop_name == my_prop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPQjE1F4r_UA"
   },
   "source": [
    "To check our work find out how many committees are left after the filter, let’s run the DataFrame inspection commands we learned earlier.\n",
    "\n",
    "First head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ix9BndGzr_UA"
   },
   "outputs": [],
   "source": [
    "my_committees.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8e2ZuHxUr_UA"
   },
   "source": [
    "Then info.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GKG2apt7r_UB"
   },
   "outputs": [],
   "source": [
    "my_committees.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PVs2H8Hr_UB"
   },
   "source": [
    "# Merge\n",
    "Our next job is to filter down the contributions list, which includes all disclosed contributions to all proposition campaigns, to just those linked to Proposition 64.\n",
    "\n",
    "We could try to do this with a filter, as we did before with the committees.\n",
    "\n",
    "But look carefully at the columns listed in the contribution file’s info output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyhxhQSMr_UB"
   },
   "outputs": [],
   "source": [
    "contrib_list.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyfKZDC6r_UB"
   },
   "source": [
    "Now compare that to the committees file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBNIWR1Ir_UB"
   },
   "outputs": [],
   "source": [
    "committee_list.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VaaUxVZ2r_UB"
   },
   "source": [
    "You will notice that this file contains a field called calaccess_committee_id that is identical to the one found in the committee CSV.\n",
    "\n",
    "That’s because these two files are drawn from a “relational database” that stores data in an array of tables linked together by common identifiers. In this case, the unique identifying codes of committees in one table can be expected to match those found in another.\n",
    "\n",
    "We can therefore safely join the two files using the pandas merge method.\n",
    "\n",
    "Note\n",
    "\n",
    "Again, if you are familar with traditional databases, you may recognize that the merge method in pandas is similar to SQL’s JOIN statement. If you dig into merge’s documentation you will see it has many of the same options, such as the ability to conduct “inner” and “outer” joins.\n",
    "\n",
    "## Merging DataFrames\n",
    "By default the merge method in pandas will return only those rows where a common identifier found in both tables, which is known as an “inner” join.\n",
    "\n",
    "That means that if we merge the full contributions file to our filtered list of Proposition 64 committees, only the contributions to the Proposition 64 committees will remain. The result will be equivalent to a filter.\n",
    "\n",
    "That’s exactly what we want. So let’s try it.\n",
    "\n",
    "Merging two DataFrames is as simple as passing both to pandas built-in merge method and specifying which field we’d like to use to connect them together. We will save the result into another new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9iwd-vmr_UB"
   },
   "outputs": [],
   "source": [
    "merged = pd.merge(my_committees, contrib_list, on=\"calaccess_committee_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdwbiRxEr_UB"
   },
   "source": [
    "That new DataFrame variable can be inspected like any other.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i4vJ0GBkr_UB"
   },
   "outputs": [],
   "source": [
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ycKMz8tr_UC"
   },
   "source": [
    "By looking at the columns you can check how many rows survived the merged.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B7_PDQFzr_UC"
   },
   "outputs": [],
   "source": [
    "merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4xq_eM0r_UC"
   },
   "source": [
    "You can also see that the DataFrame now contains all of the columns in both tables. Columns with the same name have had a suffix automatically appended to indicate whether they came from the first or second DataFrame submitted to the merge.\n",
    "\n",
    "We have now created a new dataset that includes only contributions supporting and opposing Proposition 64. We’re ready to move on from preparing our data. It’s time to interview it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O9o_6onjr_UC"
   },
   "source": [
    "# Totals\n",
    "In some ways, your database is no different from a human source. Getting a good story requires careful, thorough questioning. In this section we will move ahead by conducting an interview with pandas to pursue our quest of finding out the biggest donors to Proposition 64.\n",
    "\n",
    "Using tricks we learned as far back as chapter three, we can start off by answering a simple question: What is the total sum of Proposition 64 contributions that have been reported?\n",
    "\n",
    "## Summing a column\n",
    "To answer that let’s start by getting our hands on amount, the column from the contributions DataFrame with the numbers in it. We can do that just as we did with other columns earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kIZ-DxxKr_UC"
   },
   "outputs": [],
   "source": [
    "merged.amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_iAwK4Tr_UC"
   },
   "source": [
    "Now we can add up the column’s total using the pandas method sum, just as we did when we were first getting started with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oos1CrrTr_UC"
   },
   "outputs": [],
   "source": [
    "merged.amount.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "db8Hhy-1r_UC"
   },
   "source": [
    "And printed out below your cell, there’s our answer.\n",
    "\n",
    "We’ve completed our first piece of analysis and discovered the total amount spent on this proposition.\n",
    "\n",
    "Time to run off to Twitter and publish our results to the world, right?\n",
    "\n",
    "Wrong.\n",
    "\n",
    "## How not to be wrong\n",
    "The total we generated is not the overall total raised in the campaign, and it is guaranteed to be lower than the totals reported in the media and by the campaigns.\n",
    "\n",
    "Why?\n",
    "\n",
    "In California, campaigns are only required to disclose the names of donors who give over $100, so our data is missing all of the donors who gave less than that amount.\n",
    "\n",
    "The cutoff varies, and there are some exceptions, but the same thing is true in other states and also at the federal level in races for Congress and the White House.\n",
    "\n",
    "The overall totals are instead reported on cover sheets included with disclosure reports that lump together all the smaller contributions as part of a grand total. Those are the records most commonly cited to total up a campaign’s fundraising.\n",
    "\n",
    "The result is that an itemized list of contributions, like the one we have, cannot be used to calculate a grand total. That’s true in California and virtually anywhere else you work with campaign data. Overlooking that limitation is a rookie mistake routinely made by analysts new to this field.\n",
    "\n",
    "But that doesn’t mean our data is worthless. We just have to use it responsibly. In many cases, professional campaign reporters will refer to an analysis drawn from a list like ours as applying only to “large donors.”\n",
    "\n",
    "Since large donors typically account for most of the money, the results are still significant. And the high level of detail included in each record — like the donor’s name, employer and occupation — makes the limitations worth working through.\n",
    "\n",
    "## Which side got more large donations?\n",
    "Adding up a big total is all well and good. But we’re aiming for something more nuanced.\n",
    "\n",
    "We want to separate the money spent supporting the proposition from the money opposing it. Then we want to find out who raised more.\n",
    "\n",
    "To answer that question, let’s return to the filtering technique we learned in chapter seven.\n",
    "\n",
    "First let’s look at the column we’re going to filter by, committee_position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUJt94Kbr_UD"
   },
   "outputs": [],
   "source": [
    "merged.committee_position.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-DCRrWc4r_UD"
   },
   "source": [
    "Now let’s filter our merged table down using that column and the pandas filtering method that combines a column, an operator and the value we want to filter by. Let’s stick the result in a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6b13iPifr_UD"
   },
   "outputs": [],
   "source": [
    "support = merged[merged.committee_position == 'SUPPORT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VOxjPKWbr_UD"
   },
   "source": [
    "Now let’s repeat all that for opposing contributions. First the filter into a new variable.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2UjrP2oDr_UD"
   },
   "outputs": [],
   "source": [
    "oppose = merged[merged.committee_position == 'OPPOSE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hk-FDUTr_UD"
   },
   "source": [
    "Now sum up the total disclosed contributions to each for comparison. First the opposition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aovCUKzLr_UD"
   },
   "outputs": [],
   "source": [
    "oppose.amount.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeftfrbWr_UD"
   },
   "source": [
    "Then the supporters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wbx_DW8rr_UD"
   },
   "outputs": [],
   "source": [
    "support.amount.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMdlF8E5r_UE"
   },
   "source": [
    "The support is clearly larger. But what percent is it of the overall disclosed total? We can find out by combining two sum calculations using the division operator.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1B0DHVGer_UE"
   },
   "outputs": [],
   "source": [
    "support.amount.sum() / merged.amount.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g82xgqamr_UE"
   },
   "source": [
    "# Sorting\n",
    "Another simple but common technique for analyzing data is sorting.\n",
    "\n",
    "What were the ten biggest contributions? We can find the answer by using the sort_values method to rearrange our list using the amount field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJLSSArCr_UE"
   },
   "outputs": [],
   "source": [
    "merged.sort_values(\"amount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwWkXdyir_UE"
   },
   "source": [
    "Note that returns the DataFrame resorted in ascending order from lowest to highest. That is pandas default way of sorting.\n",
    "\n",
    "To answer our question you’ll need to reverse that, so that values are sorted in descending order from biggest to smallest. It’s a little tricky at first, but here’s how to do it with sort_values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plnVB0WXr_UE"
   },
   "outputs": [],
   "source": [
    "merged.sort_values(\"amount\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46T6pWrlr_UE"
   },
   "source": [
    "You can limit the result to the top five by chaining the head method at the end.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZwza2Har_UE"
   },
   "outputs": [],
   "source": [
    "merged.sort_values(\"amount\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cc1tICpr_UE"
   },
   "source": [
    "We can now use the new variable to rank the five biggest supporting contributions by using sort_values again.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "seBG7jter_UF"
   },
   "outputs": [],
   "source": [
    "support.sort_values(\"amount\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ceD41cyr_UF"
   },
   "source": [
    "And now how about the opposition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nUog5Ktjr_UF"
   },
   "outputs": [],
   "source": [
    "oppose.sort_values(\"amount\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TK1GolZGr_UF"
   },
   "source": [
    "# Groupby\n",
    "To take the next step towards ranking the top contributors, we’ll need to learn a new trick. It’s called groupby.\n",
    "\n",
    "It’s a pandas method that allows you to group a DataFrame by a column and then calculate a sum, or any other statistic, for each unique value. This is necessary when you want to rack up statistics on a long list of values, or about a combination of fields.\n",
    "\n",
    "## Grouping by one field\n",
    "As we’ve been digging through the data, I’m sure a few questions have popped into mind. One interesting field in the contributions list is the home state of the contributor. A natural question follows: How much of the money came from outside of California?\n",
    "\n",
    "If you scroll back up and look carefully as the info command we ran after merging out data, you will noticed it includes a column named contributor_state.\n",
    "\n",
    "That’s the field we want to group with here. Here’s how you do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RVVaOndur_UF"
   },
   "outputs": [],
   "source": [
    "merged.groupby(\"contributor_state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_khjc94Ur_UF"
   },
   "source": [
    "A nice start. But you’ll notice you don’t get much back. The data’s been grouped by state, but we haven’t chosen what to do with it yet. We want totals by state, so we can sum the amount field the same way we did earlier for the entire DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-j7HWn3r_UF"
   },
   "outputs": [],
   "source": [
    "merged.groupby(\"contributor_state\").amount.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMSiLlocr_UF"
   },
   "source": [
    "Again our data has come back as an ugly Series. To reformat it as a pretty DataFrame use the reset_index method again.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fhBKdvYjr_UG"
   },
   "outputs": [],
   "source": [
    "merged.groupby(\"contributor_state\").amount.sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhcTaxH4r_UG"
   },
   "source": [
    "Sorting the biggest totals to the top is as easy as appending the sort_values trick we already know to the end. And voila there’s our answer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GDKW2fHtr_UG"
   },
   "outputs": [],
   "source": [
    "merged.groupby(\"contributor_state\").amount.sum().reset_index().sort_values(\"amount\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zr99R-fxr_UG"
   },
   "source": [
    "## Grouping by multiple fields\n",
    "Finding the top contributors is almost as easy, but since the first and last names are spread between two fields we’ll need to submit them to groupby as a list. Copy the last line above, and replace “contributor_state” with a list like the one here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cabjbgH_r_UG"
   },
   "outputs": [],
   "source": [
    "merged.groupby([\"contributor_firstname\", \"contributor_lastname\"]).amount.sum().reset_index().sort_values(\"amount\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oNNusuzr_UG"
   },
   "source": [
    "You should be noticing that several of the top contributors appear to be the same person with their name entered in slightly different ways. This is another important lesson of campaign contributions data. Virtually none of the data is standardized by the campaigns or the government. The onus is on the analyst to show caution and responsibly combine records where the name fields refer to the same person.\n",
    "\n",
    "To find out if each contributor supported or opposed the measure, you simple add that field to our groupby method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rxGXtSlr_UG"
   },
   "outputs": [],
   "source": [
    "merged.groupby([\"contributor_firstname\", \"contributor_lastname\", \"committee_position\"]).amount.sum().reset_index().sort_values(\"amount\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhTgARnkr_UG"
   },
   "source": [
    "If you wanted just the top supporters or opponents alone, you could run those same commands with the support and oppose datasets we filtered down to earlier. Everything else about the commands would be the same as the first one above.\n",
    "\n",
    "For the supporters:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cWiei_LJr_UG"
   },
   "outputs": [],
   "source": [
    "support.groupby([\"contributor_firstname\", \"contributor_lastname\"]).amount.sum().reset_index().sort_values(\"amount\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DzlRlKmr_UH"
   },
   "source": [
    "For the opponents:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EjolFhHlr_UH"
   },
   "outputs": [],
   "source": [
    "oppose.groupby([\"contributor_firstname\", \"contributor_lastname\"]).amount.sum().reset_index().sort_values(\"amount\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PMQ6xVyr_UH"
   },
   "source": [
    "## How not to be wrong\n",
    "You’ve done it. Our brief interview is complete and you’ve answered the big question that started our inquiry.\n",
    "\n",
    "Or so you think! Look again at our rankings above. Now compare them against the ranking we looked at earlier in our sorting lesson.\n",
    "\n",
    "Study it closely and you’ll see an important difference. All of the contributors without a first name are dropped from our groupby lists. And some of them gave a lot of money.\n",
    "\n",
    "This is happening because if another pandas quirk. Empty fields are read in by pandas as null values, which is a mathematical representation of nothing. In pandas a null is called a NaN, an abbreviation for “not a number” commonly used in computer programming.\n",
    "\n",
    "And, guess what, pandas’ groupby method will drop any rows with nulls in the grouping fields. So all those records without a first name were silently excluded from our analysis. Yikes!\n",
    "\n",
    "Whatever our opinion of pandas’ default behavior, it’s something we need to account for, and a reminder that we should never assume we know what computer programming tools are doing under the hood. As with human sources, everything you code tells you should be viewed skeptically and verified.\n",
    "\n",
    "The solution to this problem is easy. We need to replace those NaN first names with empty strings, which pandas won’t drop. We can do that by using pandas’ fillna method ahead of the group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kx7d60xUr_UH"
   },
   "outputs": [],
   "source": [
    "merged.fillna(\"\").groupby([\"contributor_firstname\", \"contributor_lastname\", \"committee_position\"]).amount.sum().reset_index().sort_values(\"amount\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shxTrP99r_UH"
   },
   "source": [
    "Now we’ve finally got a ranking we can work with. Congratulations, you’ve finished our analysis.\n",
    "\n",
    "## Extra credit\n",
    "If you’re interested in continuing the interview, see if you can answer a few more questions on your own. Here are some ideas:\n",
    "\n",
    "* What are the top employers of donors for and against the measure?\n",
    "* Which committees had the fewest donors?\n",
    "* What was the average size of donations both for and against?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STRctdonr_UH"
   },
   "source": [
    "# Remix\n",
    "Now here’s where things get fun. Your entire analysis is scripted top to bottom, which means it can be rerun and reproduced. It also be remixed.\n",
    "\n",
    "Remember this line earlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ciRRuXiHr_UH"
   },
   "outputs": [],
   "source": [
    "my_prop = 'PROPOSITION 064- MARIJUANA LEGALIZATION. INITIATIVE STATUTE.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6Y1Lvf5r_UH"
   },
   "source": [
    "That’s where we set which proposition we wanted to filter on. It was a key fork in the road, which shaped all the analysis that followed.\n",
    "\n",
    "That means that if we substituted a different proposition name from the value_counts list just above it we could rerun our notebook and conduct an identical analysis of another proposition, without writing another line of code.\n",
    "\n",
    "Let’s try it. I picked the death penalty ban that was on the same ballot and changed that cell of code to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RuovvPCr_UI"
   },
   "outputs": [],
   "source": [
    "my_prop = 'PROPOSITION 062- DEATH PENALTY. INITIATIVE STATUTE.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZ8KkXEbr_UI"
   },
   "source": [
    "Now I go to the Run menu at the top of the notebook and selected “Run All Cells.” Wait a few seconds and, boom, you’ll have a whole new of donors plotted out.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "wT_GQhuVr_T6",
    "WVYjEPqQr_T6",
    "jfVigRSIr_T7",
    "qb4WYK-Fr_T8",
    "PPVXBIOwr_T8",
    "ZfA-FrQmr_T-",
    "b0AjhoMqr_T_",
    "wsGRcp0_r_T_",
    "5PMyKMTTr_T_",
    "3PVs2H8Hr_UB",
    "VaaUxVZ2r_UB",
    "O9o_6onjr_UC",
    "db8Hhy-1r_UC",
    "g82xgqamr_UE",
    "TK1GolZGr_UF",
    "zr99R-fxr_UG",
    "2PMQ6xVyr_UH",
    "shxTrP99r_UH",
    "STRctdonr_UH"
   ],
   "name": "pandas-notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "papermill": {
   "duration": 8.571866,
   "end_time": "2020-10-01T00:25:29.217110",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-01T00:25:20.645244",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
